# ml-interpretability

A Shiny app and R Notebook demonstrating the use of LIME -- Local Interpretable Model-agnostic Explanations (LIME).

The Shiny app allows users to quickly and easily build, train, and test a simple neural network in `Keras`, then use `LIME` to investigate and interpret how the model is working.

The notebook, on the other hand, walks through each process step-by-step and will be useful for users who wish to implement `LIME` for their own models.
